{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert survey data readable dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataRootFolder = './data/ss23'\n",
    "\n",
    "dataRootFolder = './data/ws2324'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from limepy.wrangle import Survey\n",
    "\n",
    "def getSurveyDataframeForExercise(number: int):\n",
    "    if not os.path.exists(f'{dataRootFolder}/exercise{number}.lss') or not os.path.exists(f'{dataRootFolder}/answers-ex{number}.csv'):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    with open(f'{dataRootFolder}/exercise{number}.lss') as surveyStructure:\n",
    "        structure = surveyStructure.read()\n",
    "\n",
    "    with open(f'{dataRootFolder}/answers-ex{number}.csv') as surveyAnswers:\n",
    "        dfEx = pd.read_csv(f'{dataRootFolder}/answers-ex{number}.csv', sep=',')\n",
    "\n",
    "    survey = Survey(dfEx, structure, language='en')\n",
    "    survey.readable_df['survey'] = number\n",
    "\n",
    "    surveyUsableAnswers = survey.readable_df[\n",
    "        survey.readable_df['Can we use your anonymous response for research, including publications, and future development of Jayvee?'] == 'Yes'\n",
    "        ]\n",
    "\n",
    "    return surveyUsableAnswers\n",
    "\n",
    "\n",
    "allSurveys = pd.concat([getSurveyDataframeForExercise(x) for x in range(1, 6)])\n",
    "\n",
    "allSurveys = allSurveys.rename(columns={\n",
    "    'What programming language did you use to solve the exercise?': 'language',\n",
    "    'Can we use your anonymous response for research, including publications, and future development of Jayvee?': 'optin',\n",
    "    'How many hours did you spend to solve the exercise?': 'time',\n",
    "    'How difficult was it to solve the exercise using your programming language?': 'difficulty',\n",
    "    'How would you rate the quality of the resulting data pipeline?': 'quality',\n",
    "    'What problems with the programming language did you encounter during this exercise?': 'problems',\n",
    "    'What language features or libraries would have made solving the exercise easier?': 'features',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export free text fields to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportQuestion(df, question: str, questionCode: str, exerciseNumber: int):\n",
    "    exportString = f'# {question}\\n\\n'\n",
    "    \n",
    "    dfToExport = df[\n",
    "                    [\n",
    "                        'language',\n",
    "                        questionCode\n",
    "                    ]\n",
    "                ].dropna().sort_values('language')\n",
    "    \n",
    "    exportString += '## Jayvee\\n\\n'\n",
    "\n",
    "    for answer in dfToExport[dfToExport['language'] == 'Jayvee'][questionCode]:\n",
    "        exportString += answer + '\\n-----------\\n'\n",
    "    \n",
    "    exportString += '## Python\\n\\n'\n",
    "\n",
    "    for answer in dfToExport[dfToExport['language'] == 'Python'][questionCode]:\n",
    "        exportString += answer + '\\n-----------\\n'\n",
    "\n",
    "    with open(f'{dataRootFolder}/generated/freetext/{\"\".join([x if x.isalnum() else \"_\" for x in question][:20])}{exerciseNumber}.txt', 'w+') as f:\n",
    "        f.writelines(exportString)\n",
    "\n",
    "for surveyId in range(1, 6):\n",
    "    exportQuestion(\n",
    "        allSurveys[allSurveys['survey'] == surveyId],\n",
    "        'What problems with the programming language did you encounter during this exercise?',\n",
    "        'problems',\n",
    "        surveyId\n",
    "    )\n",
    "    exportQuestion(\n",
    "        allSurveys[allSurveys['survey'] == surveyId],\n",
    "        'What language features or libraries would have made solving the exercise easier?',\n",
    "        'features',\n",
    "        surveyId\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop not needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not needed data\n",
    "data = allSurveys.drop(['id', 'lastpage', 'submitdate', 'startlanguage', 'seed', 'optin', 'problems', 'features'], axis=1)\n",
    "\n",
    "data.to_csv(f'{dataRootFolder}/generated/survey-responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all semesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataRootFolder = './data'\n",
    "\n",
    "allEntryExitSurveys = {\n",
    "    'ss23': f'{dataRootFolder}/ss23/generated/entry-exit-anon.csv',\n",
    "    'ws2324': f'{dataRootFolder}/ws2324/generated/entry-exit-anon.csv'\n",
    "}\n",
    "\n",
    "allEntryExitSurveysDfs = []\n",
    "\n",
    "for semester in allEntryExitSurveys:\n",
    "    df = pd.read_csv(allEntryExitSurveys[semester])\n",
    "    df['semester'] = semester\n",
    "    allEntryExitSurveysDfs.append(df)\n",
    "    \n",
    "dfCombined = pd.concat(allEntryExitSurveysDfs, ignore_index=True, verify_integrity=True).fillna(False)\n",
    "\n",
    "dfCombined.to_csv(f'{dataRootFolder}/generated/entry-exit-anon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataRootFolder = './data'\n",
    "\n",
    "allSurveyResponses = {\n",
    "    'ss23': f'{dataRootFolder}/ss23/generated/survey-responses.csv',\n",
    "    'ws2324': f'{dataRootFolder}/ws2324/generated/survey-responses.csv'\n",
    "}\n",
    "\n",
    "\n",
    "allSurveyResponsesDfs = []\n",
    "\n",
    "for semester in allSurveyResponses:\n",
    "    df = pd.read_csv(allSurveyResponses[semester])\n",
    "    df['semester'] = semester\n",
    "    allSurveyResponsesDfs.append(df)\n",
    "    \n",
    "dfCombined = pd.concat(allSurveyResponsesDfs, ignore_index=True, verify_integrity=True).fillna(False)\n",
    "\n",
    "dfCombined.to_csv(f'{dataRootFolder}/generated/survey-responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "dataRootFolder = './data'\n",
    "\n",
    "allFreetextResponses = {\n",
    "    'ss23': f'{dataRootFolder}/ss23/generated/freetext',\n",
    "    'ws2324': f'{dataRootFolder}/ws2324/generated/freetext'\n",
    "}\n",
    "\n",
    "for semester in allFreetextResponses:\n",
    "    folder = allFreetextResponses[semester]\n",
    "    shutil.copytree(folder, f'{dataRootFolder}/generated/freetext', dirs_exist_ok=True)\n",
    "\n",
    "    filenames = [filename for filename in os.listdir(f'{dataRootFolder}/generated/freetext') if not filename.startswith(\"semester_\")]\n",
    "\n",
    "    for filename in filenames:\n",
    "        os.rename(f'{dataRootFolder}/generated/freetext/{filename}', f'{dataRootFolder}/generated/freetext/semester_{semester}_{filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
